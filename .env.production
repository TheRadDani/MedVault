# Environment Configuration - Copy to .env for production
# DO NOT commit .env to version control

# Ollama Configuration
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_NUM_PARALLEL=2
OLLAMA_NUM_GPU=-1  # -1 = all available VRAM
OLLAMA_KEEP_ALIVE=5m

# Model Configuration
DEFAULT_MODEL=mistral  # llama3
EMBEDDING_MODEL=bge-small # sentence-transformers/all-MiniLM-L6-v2

# App Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_HEADLESS=true

# Performance Tuning (GPU)
CUDA_VISIBLE_DEVICES=0  # Comma-separated GPU IDs
CUDA_LAUNCH_BLOCKING=0  # Enable for debugging

# Logging
LOG_LEVEL=INFO

# RAG Configuration
MAX_CONTEXT_LENGTH=2048
TOP_K_RETRIEVAL=5
# Encryption Configuration (Optional - for sensitive medical data)
# Generate key: python -c "from src.encryption import EncryptionManager; print(EncryptionManager.generate_key())"
# Option 1: Use encryption key directly (Fernet base64-encoded)
ENCRYPTION_KEY=RozDwt7aOHECDtspdeCn7MLAms92Q-KjFzaNJfN07ew=
# Option 2: Use password-based encryption (PBKDF2 derived from password)
ENCRYPTION_PASSWORD=
# Enable/disable encryption
ENCRYPT_DATA_AT_REST=true
ENCRYPTED_DATA_DIR=data/encrypted