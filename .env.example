# Environment Configuration - Copy to .env for production
# DO NOT commit .env to version control

# Ollama Configuration
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_NUM_PARALLEL=4
OLLAMA_NUM_GPU=-1  # -1 = all available VRAM
OLLAMA_KEEP_ALIVE=5m

# Model Configuration
DEFAULT_MODEL=mistral  # Change to your preferred model
EMBEDDING_MODEL=bge-small

# App Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_HEADLESS=true

# Performance Tuning (GPU)
CUDA_VISIBLE_DEVICES=0  # Comma-separated GPU IDs
CUDA_LAUNCH_BLOCKING=0  # Enable for debugging

# Logging
LOG_LEVEL=INFO

# RAG Configuration
MAX_CONTEXT_LENGTH=2048
TOP_K_RETRIEVAL=5
